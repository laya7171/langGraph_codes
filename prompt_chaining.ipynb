{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "032da4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "from langchain.prompts import PromptTemplate\n",
    "from typing import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0b3138e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OllamaLLM(model=\"gemma3:1b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4e36ef47",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Blogstate(TypedDict):\n",
    "    topic: str\n",
    "    outline: str\n",
    "    content: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "39fc2cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(Blogstate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a46c0948",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_outline(state: Blogstate) -> Blogstate:\n",
    "    title = state['topic']\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"Create a small outline for a blog post about {title}.\",\n",
    "        input_variables=[\"title\"]\n",
    "    )\n",
    "\n",
    "    response = llm.invoke(prompt.format(title=title))\n",
    "\n",
    "    state['outline'] = response\n",
    "    return state\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a2f99faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_blog(state: Blogstate) -> Blogstate:\n",
    "    outline = state['outline']\n",
    "    prompt = PromptTemplate(\n",
    "        template= \"write me a small blog about the following outline: {outline}\",\n",
    "        input_variables=[\"outline\"]\n",
    "    )\n",
    "\n",
    "    response = llm.invoke(prompt.format(outline=outline))\n",
    "\n",
    "    state['content'] = response\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "25946af3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x28890047070>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.add_node(\"create_outline\", create_outline)\n",
    "graph.add_node(\"create_blog\", create_blog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b6b6d797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x28890047070>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.add_edge(START, \"create_outline\" )\n",
    "graph.add_edge(\"create_outline\", \"create_blog\")\n",
    "graph.add_edge(\"create_blog\", END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a1bc8cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0a637afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = {\n",
    "    'topic': \"How to use LangGraph with Ollama\"\n",
    "}\n",
    "final_state = workflow.invoke(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "af88f21e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'topic': 'How to use LangGraph with Ollama', 'outline': 'Okay, here’s a small outline for a blog post about How to use LangGraph with Ollama, designed to be informative and helpful for beginners:\\n\\n**Blog Post Title: Unleash Your LLM Potential: A Beginner\\'s Guide to LangGraph with Ollama**\\n\\n**I. Introduction (approx. 100-150 words)**\\n\\n*   Hook: Briefly explain the power of LangGraph – it’s a fantastic tool for understanding and improving LLM performance.\\n*   What is LangGraph? (Keep it simple - a graph visualization of LLM behavior)\\n*   Why use it with Ollama? (Highlight the benefits: easier debugging, insight, potential improvements)\\n*   Briefly state the post\\'s goal: “This guide will walk you through setting up and using LangGraph with Ollama to gain valuable insights into your LLM’s responses.”\\n\\n\\n**II. What is LangGraph? (approx. 100-150 words)**\\n\\n*   Explain the core concept: LangGraph is a graph-based visualization tool for LLM behavior.\\n*   Key Features: Briefly mention its ability to show:\\n    *   LLM confidence levels\\n    *   Connections/dependencies between tokens\\n    *   Potential bias\\n*   Mention it’s beneficial for troubleshooting and optimization\\n\\n\\n**III. Setting Up LangGraph with Ollama (approx. 200-300 words)**\\n\\n*   **Step 1: Install Ollama:** Provide a link to the Ollama website and instructions on how to install it (for beginners).\\n*   **Step 2:  Configure Ollama:**  Explain how to set up Ollama (running it, specifying the model).\\n*   **Step 3:  Run LangGraph:**  Guide on how to start the LangGraph session:\\n    *   Using the `ollama run langgraph` command.\\n    *   Explain the basic interface (graph view, node types).\\n\\n**IV. Using LangGraph:  Examples & Key Concepts (approx. 200-300 words)**\\n\\n*   **Example 1:  Simple Prompt - Explore Confidence:** Demonstrate how to use LangGraph to see if the model is confident about different prompts.\\n*   **Example 2:  Analyzing Connections:**  Show how to visualize connections between tokens to identify potential issues (e.g., a token that\\'s frequently linked to a problematic word).\\n*   **Key Features to Highlight:**\\n    *   **Node Types:** Explain the different node types (e.g., \"Confidence\", \"Token\", \"Context\").\\n    *   **Edge Colors/Widths:**  Briefly touch on how to use these for visual cues.\\n*   **Interactive Visualization:**  Mention the ability to interact with the graph (e.g., zoom, pan, explore nodes).\\n\\n\\n**V. Conclusion (approx. 50-100 words)**\\n\\n*   Recap the benefits of using LangGraph.\\n*   Encourage experimentation – prompt and try out different scenarios.\\n*   Call to action: \"Try it out and see how LangGraph can help you improve your LLM experience!\"\\n\\n**Resources (Optional - 100-200 words)**\\n\\n*   Link to the official LangGraph documentation.\\n*   Link to the Ollama documentation.\\n\\n---\\n\\n**Notes & Considerations:**\\n\\n*   **Target Audience:**  Assume readers have *very* basic knowledge of LLMs.\\n*   **Keep it Concise:**  Use clear, simple language.\\n*   **Visuals:**  Consider adding a screenshot of the LangGraph interface to make the post more engaging.\\n*   **Keep it Focused:** Don\\'t try to cover *everything* about LangGraph.  Focus on the most important aspects.\\n\\nTo help me refine this outline further, could you tell me:\\n\\n*   Who is the target audience for this blog post (e.g., beginners, LLM enthusiasts)?\\n*   Are there any specific areas you want to emphasize (e.g., debugging)?', 'content': 'Okay, great! Thanks for the feedback. Here\\'s a slightly tweaked version of the blog post outline, keeping in mind the target audience of beginners who are just starting to explore LLMs.\\n\\n**Blog Post Title: Unlock LLM Insights: A Beginner\\'s Guide to LangGraph with Ollama**\\n\\n**I. Introduction (approx. 120-180 words)**\\n\\n*   Hook: Start with a relatable scenario – \"Ever felt like your LLM isn’t giving you the answers you need? LangGraph can be a powerful detective tool.\"\\n*   What is LangGraph? – \"LangGraph is a visual graph tool designed to understand how an LLM is responding to your prompts. Think of it as a map of what’s happening inside the model\\'s ‘brain’.\"\\n*   Why use it with Ollama? – \"Ollama makes it easier to debug and optimize your LLM responses. It helps you quickly see where things are going wrong and identify potential areas for improvement.\"\\n*   Post Goal: “This guide will show you how to easily set up and use LangGraph with Ollama to gain insights into your LLM’s behavior.”\\n\\n**II. What is LangGraph? (approx. 150-220 words)**\\n\\n*   Explain the core concept: “LangGraph uses nodes and edges to represent tokens, confidence levels, and relationships. It shows you the model\\'s \\'thought process\\' visually.\"\\n*   Key Features – focusing on the *most* important ones for beginners:\\n    *   **Node Types:** Explain node types like \"Confidence,\" \"Token,\" \"Context,\" and \"Bias.\"  Use simple, easy-to-understand examples.\\n    *   **Connections:**  \"Edges represent dependencies – if the model is focusing on ‘X’ after seeing ‘Y’, it might rely on ‘Z’ more.”\\n    *   **Visualizing Bias:** Highlight the ability to spot patterns in the graph that might indicate biases.\\n*   Benefit: “It\\'s like a detective\\'s view of your LLM’s reasoning – showing potential problems and helping you understand why it’s making certain choices.”\\n\\n**III. Setting Up LangGraph with Ollama (approx. 250-350 words)**\\n\\n*   **Step 1: Install Ollama:** Provide a clear, concise link to the Ollama website and detailed, step-by-step instructions (avoiding overly technical jargon).  Include a small, engaging animation of the installation process if possible.\\n*   **Step 2: Configure Ollama:** Explain how to run Ollama, specify the model, and adjust settings (e.g., temperature).\\n*   **Step 3: Run LangGraph:** Guide on how to start the LangGraph session:\\n    *   Using the `ollama run langgraph` command.\\n    *   Explain the interface – “It’s like a mind map; nodes represent tokens, edges represent relationships.”  Emphasize the core concept of clicking on nodes to explore.\\n\\n**IV. Using LangGraph:  Examples & Key Concepts (approx. 200-300 words)**\\n\\n*   **Example 1: Simple Prompt - Explore Confidence:** Demonstrate a quick, visually clear example of prompting and seeing the model’s confidence levels visualized.\\n*   **Example 2: Analyzing Connections –  Positive Bias:** Show how to click on a token that’s frequently linked to a word that’s consistently positive.  Illustrate the node’s color changes to show this connection.\\n*   **Key Features to Highlight:**\\n    *   **Node Types:** Again, explain the meaning of the different node types.\\n    *   **Edge Colors/Widths:**  Briefly touch on how these visual cues can help interpret the graph.\\n    *   **Interactive Zooming:**  \"You can click and drag to explore different areas of the graph.\"\\n*   **Interactive Visualization:**  “Observe how the nodes connect and rearrange themselves as you change the prompt – it’s a visual way to see the model\\'s thought process.\"\\n\\n\\n**V. Conclusion (approx. 50-100 words)**\\n\\n*   Recap the benefits – “LangGraph helps you quickly identify issues, understand model behavior, and optimize responses.”\\n*   Encourage experimentation – “Try different prompts and see how the graph reacts! Experiment with different nodes, colors, and edges.”\\n*   Call to Action: “Start experimenting with LangGraph today – it\\'s a free and incredibly powerful tool!”\\n\\n**Resources (Optional - 100-200 words)**\\n\\n*   Link to the official LangGraph documentation.\\n*   Link to the Ollama documentation.\\n\\n---\\n\\nLet\\'s refine this further.  Do you think these additions are helpful?  Would you like me to tweak anything in particular (e.g., the tone, the level of detail for the examples)?'}\n"
     ]
    }
   ],
   "source": [
    "print(final_state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
